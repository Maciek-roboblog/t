Dobrze â€” oto **rozszerzenie poprzedniego dokumentu** z wyjaÅ›nieniem dokÅ‚adnie **jak LLaMAâ€‘Factory dziaÅ‚a**, w tym jakie zdarzenia i triggery wystÄ™pujÄ…, kiedy interakcja uÅ¼ytkownika wywoÅ‚uje procesy, oraz jak to siÄ™ wpisuje w architekturÄ™, ktÃ³rÄ… juÅ¼ mamy. MoÅ¼esz to wÅ‚Ä…czyÄ‡ do dokumentacji projektowej.

---

## ðŸ”„ Jak dziaÅ‚a caÅ‚y workflow â€“ â€žco, kiedy i jakâ€ w LLaMA-Factory

### 1. UÅ¼ytkownik â†’ WebUI / CLI / YAML

* UÅ¼ytkownik koÅ„cowy lub analityk wchodzi w interfejs WebUI LLaMA-Factory (np. uruchamiajÄ…c `llamafactory-cli webui`). ([docs.swanlab.cn][1])
* Alternatywnie DevOps/Data Scientist przygotowuje plik YAML/JSON (konfiguracjÄ™ treningu) lub uÅ¼ywa CLI: np. `llamafactory-cli train --config train_config.yaml`. ([docs.swanlab.cn][1])
* W WebUI uÅ¼ytkownik wybiera: model bazowy, metodÄ™ fine-tuningu (LoRA/QLoRA), dataset, hiper-parametry, miejsce zapisu outputu. ([datacamp.com][2])
* Po klikniÄ™ciu â€žStartâ€ w UI lub po wywoÅ‚aniu CLI nastÄ™puje zapis konfiguracji (model, dataset, hiper-parametry) jako pliku YAML/JSON w repozytorium (Git). To dziaÅ‚a jako trigger dla dalszych krokÃ³w.

### 2. Trigger w repozytorium â†’ CI/CD

* Zapis (commit) pliku konfiguracji lub kodu w repozytorium Git wyzwala pipeline CI (Continuous Integration). Plik konfiguracji moÅ¼e zawieraÄ‡ metadane (np. wersjÄ™ datasetu, hash komitu, hiper-parametry).
* CI pipeline wykonuje: budowÄ™ obrazu Docker (jeÅ›li przewidziane), walidacjÄ™ pliku YAML (czy wszystkie wymagane pola sÄ… wypeÅ‚nione), testy (np. czy dataset istnieje, czy model bazowy jest dostÄ™pny).
* Po pomyÅ›lnym CI, pipeline CD (Continuous Delivery) uruchamia manifesty K8s lub inne mechanizmy deployu â€” np. Job treningowy albo Deployment dla serwisu inferencji.

### 3. Deployment w Kubernetes + start treningu

* Manifest K8s (Job) definiuje obraz kontenera (z LLaMA-Factory i zaleÅ¼noÅ›ciami), zasoby GPU (`nvidia.com/gpu: "n"`), woluminy dla danych i outputu, zmienne Å›rodowiskowe.
* Po wykonaniu `kubectl apply` lub przez CD pipeline K8s API przydziela podowi wÄ™zeÅ‚ z GPU.
* Kontener startuje: wewnÄ…trz dziaÅ‚a LLaMA-Factory â€“ komponenty Model Loader, Data Worker, Trainer sÄ… uruchamiane zgodnie z konfiguracjÄ….
* Model Loader Å‚aduje bazowy model i adaptery; Data Worker przygotowuje dane; Trainer rozpoczyna fine-tuningu lub trening rozproszony (multi-GPU/multi-node) - LLaMA-Factory wspiera to. ([Llama Factory][3])
* W trakcie dziaÅ‚ania: logi, metryki (loss, accuracy, GPU usage) sÄ… emitowane â€“ uÅ¼ytkownik/DevOps moÅ¼e monitorowaÄ‡ stan.
* Po zakoÅ„czeniu treningu artefakt modelu (checkpointy, adaptery) zostaje zapisany w output-dir lub wysÅ‚any do Model Registry (lub zewnÄ™trznego magazynu modeli) wraz z metadanymi (dataset wersja, konfiguracja, commit hash).

### 4. Serwis inferencji

* Po treningu lub niezaleÅ¼nie po wybraniu modelu moÅ¼na uruchomiÄ‡ serwis inferencyjny (np. `llamafactory-cli api config.yaml`) lub K8s Deployment + Service. ([datacamp.com][2])
* Serwis Å‚aduje odpowiedni model (na podstawie metadanych/artefaktu) z model registry lub lokalnego katalogu.
* TÄ™ warstwÄ™ moÅ¼na autoskalowaÄ‡ â€“ np. Horizontal Pod Autoscaler (HPA) reaguje na zapytania, ruch, latencjÄ™ i skaluje liczbÄ™ replik.
* UÅ¼ytkownik koÅ„cowy (aplikacja) wysyÅ‚a zapytanie do endpointu API, model odpowiada.

### 5. Monitoring, retraining i cykl MLOps

* Monitoring zbiera metryki: wydajnoÅ›Ä‡ modelu, bÅ‚Ä™dy, drift danych (czy model przestaÅ‚ speÅ‚niaÄ‡ oczekiwania).
* JeÅ›li warunki speÅ‚nione (np. nowy dataset, zmiana domeny, wykryty drift, nowy commit konfiguracji), trigger retrain jest aktywowany â€“ czyli proces wraca do kroku 1 lub 3: nowa konfiguracja â†’ CI/CD â†’ trening â†’ serwis.
* CaÅ‚y cykl zapewnia Å›ledzalnoÅ›Ä‡: konfiguracja (model/dane/hiperparametry) jest zapisana w repozytorium, kod jest wersjonowany, artefakty modelu zachowane â€“ co umoÅ¼liwia odtworzenie eksperymentu.

---

## ðŸ“Š Diagram ze szczegÃ³Å‚owymi triggerami i przepÅ‚ywami

```mermaid
sequenceDiagram
    participant User as UÅ¼ytkownik
    participant WebUI as LLaMA-Factory WebUI
    participant CLI as LLaMA-Factory CLI/YAML
    participant Repo as Git Repo (Code+Config+DataHooks)
    participant CI as CI Pipeline
    participant CD as CD Pipeline
    participant K8s as Kubernetes API
    participant Pod as Training Pod
    participant ModelReg as Model Registry
    participant Serve as Inference Service
    participant Monitor as Monitoring System

    User->>WebUI: wybiera model, dataset, hiper-parametry
    WebUI->>Repo: zapis config.yaml + metadane (dataset id, hp id, commit hash)
    CLI->>Repo: commit konfiguracji / kodu
    Repo->>CI: commit trigger pipeline
    CI->>CI: build image / validate config
    CI->>CD: image ready / config validated
    CD->>K8s: apply TrainingJob manifest (image + config)
    K8s->>Pod: schedule pod wÄ™zeÅ‚ GPU
    Pod->>Pod: Model Loader â†’ Data Worker â†’ Trainer
    Pod->>ModelReg: save model artefact + metadata
    User->>Serve: send infer-request
    Serve->>ModelReg: load latest model
    Serve-->>User: return response
    Monitor->>CD: detection of drift or new config â†’ retrain trigger
    CD-->>Repo: update config version or new commit
```

---

JeÅ›li chcesz â€” mogÄ™ wygenerowaÄ‡ **kompletny plik Markdown** zawierajÄ…cy caÅ‚y dokument + diagramy + krok po kroku trigger workflow + **szablon YAML pliku konfiguracji** z miejscami na metadane commit hash, dataset version itp.

[1]: https://docs.swanlab.cn/en/guide_cloud/integration/integration-llama-factory.html?utm_source=chatgpt.com "LLaMA Factory | SwanLab Docs"
[2]: https://www.datacamp.com/de/tutorial/llama-factory-web-ui-guide-fine-tuning-llms?utm_source=chatgpt.com "LlaMA-Factory WebUI Beginner's Guide: Fine-Tuning LLMs"
[3]: https://llamafactory.readthedocs.io/en/latest/?utm_source=chatgpt.com "Welcome to LLaMA Factory!"

---

### Diagram A: Struktura komponentÃ³w na Kubernetes

```mermaid
graph TD
    subgraph USER_LAYER
        UI[WebUI LLaMA-Factory]
        CLI[CLI / YAML Config]
    end
    subgraph REPO_LAYER
        Repo[Git Repo<br/>Code + Config + Dataset-metadata]
    end
    subgraph PIPELINE_LAYER
        CI[CI Pipeline<br/>Build/Test/Validate]
        CD[CD Pipeline<br/>Deploy Training & Serving]
    end
    subgraph K8S_LAYER
        API[Kubernetes API Server]
        NodePool[GPU Node Pool<br/>nvidia.com/gpu]
        Pods[Pods w K8s<br/>z GPU]
    end
    subgraph LLAMA_FACTORY_LAYER
        ML[Model Loader]
        DW[Data Worker]
        T[Trainer Distributed]
    end
    subgraph SERVING_LAYER
        ServePod[Inference Service Pod]
        HPA[Horizontal Pod Autoscaler]
    end
    subgraph EXTERNAL_RESOURCES
        DataStore[Dataset Storage / Object Storage]
        ModelReg[Model & Artifact Registry]
    end

    UI --> Repo
    CLI --> Repo
    Repo --> CI
    CI --> CD
    CD --> API
    API --> NodePool
    NodePool --> Pods
    Pods --> LLAMA_FACTORY_LAYER
    LLAMA_FACTORY_LAYER --> ModelReg
    LLAMA_FACTORY_LAYER --> DataStore
    ModelReg --> ServePod
    ServePod --> HPA
    ServePod --> EndUser[End-User / Aplikacja]
    EndUser --> ServePod
    HPA --> ServePod
```

---

### Diagram B: PrzepÅ‚yw operacyjny (workflow)

```mermaid
sequenceDiagram
    participant User as UÅ¼ytkownik
    participant WebUI as LLaMA-Factory WebUI
    participant CLI as LLaMA-Factory CLI/YAML
    participant Repo as Git Repo (Code+Config+DataHooks)
    participant CI as CI Pipeline
    participant CD as CD Pipeline
    participant K8s as Kubernetes API
    participant Pod as Training Pod (GPU)
    participant ModelReg as Model Registry
    participant Serve as Inference Service
    participant Monitor as Monitoring System

    User->>WebUI: wybiera model + dane + hiper-parametry
    WebUI->>Repo: zapis config.yaml + metadane
    CLI->>Repo: commit konfiguracji / kodu
    Repo->>CI: commit trigger pipeline
    CI->>CI: build image / validate config
    CI->>CD: image ready / config validated
    CD->>K8s: apply TrainingJob manifest (image + config)
    K8s->>Pod: schedule pod wÄ™zeÅ‚ GPU
    Pod->>Pod: Model Loader â†’ Data Worker â†’ Trainer
    Pod->>ModelReg: save model artefact + metadata
    User->>Serve: wysyÅ‚a zapytanie inferencyjne
    Serve->>ModelReg: Å‚aduje odpowiedni model
    Serve-->>User: zwraca wynik
    Monitor->>CD: detekcja driftu lub nowej konfiguracji â†’ retrain trigger
    CD-->>Repo: update config / new commit
```
