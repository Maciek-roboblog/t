# Job do treningu - uruchamiany ręcznie lub przez Jenkins/Airflow
# Użycie: kubectl apply -f 06-training-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: llama-train
  namespace: llm-training
  labels:
    app: llama-train
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 86400  # Usuń job po 24h
  template:
    metadata:
      labels:
        app: llama-train
    spec:
      restartPolicy: Never
      containers:
      - name: trainer
        # ZMIEŃ na swój registry
        image: eu.gcr.io/PROJECT_ID/llama-factory-train:latest
        command: ["/bin/bash", "-c"]
        args:
        - |
          echo "=== Start treningu ==="
          echo "MLFlow: $MLFLOW_TRACKING_URI"

          # Uruchom trening
          llamafactory-cli train /config/train.yaml

          echo "=== Trening zakończony ==="

          # Opcjonalnie: rejestracja w MLFlow
          python -c "
          import mlflow
          import os
          mlflow.set_tracking_uri(os.environ['MLFLOW_TRACKING_URI'])
          mlflow.set_experiment('llama-finetune')
          with mlflow.start_run(run_name='lora-model'):
              mlflow.log_artifacts('/output/lora-model', 'model')
              print('Model zarejestrowany w MLFlow')
          "
        env:
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            secretKeyRef:
              name: mlflow-config
              key: MLFLOW_TRACKING_URI
        volumeMounts:
        - name: storage
          mountPath: /models
          subPath: models
        - name: storage
          mountPath: /output
          subPath: output
        - name: storage
          mountPath: /data
          subPath: data
        - name: config
          mountPath: /config
        resources:
          requests:
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "8"
            memory: "32Gi"
            nvidia.com/gpu: "1"
      # Toleracja dla GPU nodes
      tolerations:
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"
      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: llama-storage
      - name: config
        configMap:
          name: train-config
