# LLaMA-Factory API Image (vLLM)
# Obraz do inference

FROM debian:12

ENV DEBIAN_FRONTEND=noninteractive \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

# System + Python 3.11
RUN apt-get update && apt-get install -y --no-install-recommends \
    python3.11 \
    python3-pip \
    build-essential \
    git \
    curl \
    ca-certificates \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Linki
RUN ln -sf /usr/bin/python3.11 /usr/bin/python && \
    ln -sf /usr/bin/pip3 /usr/bin/pip

# PyTorch + CUDA 11.8
RUN pip install --upgrade pip && \
    pip install \
      torch==2.2.0 \
      torchvision==0.17.0 \
      --extra-index-url https://download.pytorch.org/whl/cu118

# vLLM + Transformers + MLFlow
RUN pip install \
    transformers==4.37.0 \
    vllm==0.4.0 \
    "llamafactory[torch]==0.9.3" \
    mlflow==2.10.0

WORKDIR /app

EXPOSE 8000

# Domyślne uruchomienie - można nadpisać w K8s
CMD ["python", "-m", "vllm.entrypoints.openai.api_server", "--host", "0.0.0.0", "--port", "8000"]
