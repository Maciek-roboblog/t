@startuml tuning-strategy
!theme plain
skinparam backgroundColor #FEFEFE

title Strategia Tuning Hiperparametrow

|Baseline|
start
:Krok 1: Baseline
lora_rank: 8
lora_alpha: 16
learning_rate: 1e-4
epochs: 3;

|Underfitting|
if (Loss nie spada?) then (tak)
  :Zwieksz lora_rank: 16, 32
  Zwieksz learning_rate: 2e-4
  Zwieksz epochs: 5, 10;
else (nie)
endif

|Overfitting|
if (Val_loss rosnie?) then (tak)
  :Zmniejsz lora_rank: 4
  Zwieksz lora_dropout: 0.1, 0.15
  Zmniejsz epochs
  Dodaj early stopping;
else (nie)
endif

|OOM|
if (Brak pamieci?) then (tak)
  :Uzyj QLoRA (quantization_bit: 4)
  Zmniejsz cutoff_len
  Zmniejsz batch_size
  Wlacz gradient_checkpointing;
else (nie)
endif

stop

@enduml
