# vLLM Inference Server
#
# Serwer inference dla modeli LLM
# API kompatybilne z OpenAI (POST /v1/chat/completions)
#
# ŹRÓDŁA:
# - https://docs.vllm.ai/en/latest/deployment/k8s.html
# - https://github.com/vllm-project/production-stack
#
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm
  namespace: llm-basic
  labels:
    app: vllm
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm
  template:
    metadata:
      labels:
        app: vllm
    spec:
      containers:
      - name: vllm
        image: vllm/vllm-openai:latest
        args:
        - "--model"
        - "/storage/models/merged-model"
        - "--served-model-name"
        - "$(SERVED_MODEL_NAME)"
        - "--host"
        - "0.0.0.0"
        - "--port"
        - "8000"
        - "--max-model-len"
        - "$(MAX_MODEL_LEN)"
        - "--tensor-parallel-size"
        - "$(TENSOR_PARALLEL_SIZE)"
        - "--gpu-memory-utilization"
        - "$(GPU_MEMORY_UTILIZATION)"

        ports:
        - containerPort: 8000
          name: http

        envFrom:
        - configMapRef:
            name: llm-config

        volumeMounts:
        - name: storage
          mountPath: /storage
          readOnly: true

        resources:
          requests:
            cpu: "2"
            memory: "8Gi"
            nvidia.com/gpu: "1"
          limits:
            cpu: "4"
            memory: "16Gi"
            nvidia.com/gpu: "1"

        # Health checks
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 120
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 60
          periodSeconds: 10

      volumes:
      - name: storage
        persistentVolumeClaim:
          claimName: llm-storage
---
apiVersion: v1
kind: Service
metadata:
  name: vllm
  namespace: llm-basic
spec:
  type: ClusterIP
  selector:
    app: vllm
  ports:
  - port: 8000
    targetPort: 8000
    name: http
